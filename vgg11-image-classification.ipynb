{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Fine-Tuning the VGG-11 Neural Net Image Model (CNN) for Masked-Face Recognition </h2>\n",
    "\n",
    "**Avyay Kuchibotla**\n",
    "\n",
    "**********\n",
    "<h5>Below, we will fine-tune a pretrained model with our own images of people wearing masks, and \"teach\" the model to \"recognize\" people who are wearing masks.\n",
    "<br/>\n",
    "\n",
    "A simple use case for this would be face-unlocking your iPhone during COVID days with a mask on (when this project was first written)\n",
    "</h5>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "**PyTorch (Torch)** - ML framework with tensor computations, strong GPU acceleration (find yourself a nice NVIDIA runtime), and deep neural nets such as the VGG-11 model used in this tutorial\n",
    "\n",
    "**TorchVision** - contains image datasets (such as the one upon which the pretrained model we use has been trained), model architectures, and image data transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports; can be found in accompanying requirements.txt\n",
    "# For this project, we will be using the PyTorch framework\n",
    "\n",
    "# ... to stay consistent between Python 2 & 3\n",
    "from __future__ import print_function, division\n",
    "\n",
    "# ... PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn # neural nets\n",
    "import torch.optim as optim # optimizers\n",
    "\n",
    "# ... TorchVision (used for image datasets and manipulation for pre-training)\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# ... for data handling\n",
    "import numpy as np\n",
    "\n",
    "# ... general utilities\n",
    "import time, os, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that PyTorch & TorchVision have been successfully installed\n",
    "print( \"PyTorch\", torch.__version__ )\n",
    "print( \"TorchVision\", torchvision.__version__ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading our fine-tuning dataset from Kaggle\n",
    "\n",
    "I have uploaded a dataset with training, validation, and testing images of people wearing masks to Kaggle (completely public). Be sure to set up a Kaggle API key (in a properly-placed ~/.kaggle/kaggle.json chmod'ded +600)!\n",
    "\n",
    "Then you can either run the below function, which will perform all the installs, downloads, and unzips to bring the dataset to your working directory. Or download it <a href = \"https://www.kaggle.com/datasets/squanch/maskimageset\"> here </a>!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEFORE RUNNING THIS CELL MAKE SURE YOU HAVE A KAGGLE API KEY\n",
    "# Place it in ~/.kaggle/kaggle.json (and chmod +600 if you like to be safe)\n",
    "# NOTE: If you're on Windows, look in your C drive and re-examine your OS choices\n",
    "\n",
    "# This is over-engineered! I suggest doing this manually for your own edification and enrichment\n",
    "\n",
    "def downloadAndUnzipData():\n",
    "\n",
    "    # If data is already present, return\n",
    "    if os.path.exists( './mask_image_set/' ):\n",
    "        print( 'Dataset already exists in the working directory.' )\n",
    "        return\n",
    "\n",
    "    # Install Kaggle API client if not already installed\n",
    "    try:\n",
    "        __import__( 'kaggle' )\n",
    "\n",
    "    except ( ModuleNotFoundError, ImportError ):\n",
    "        pip = __import__( 'pip' )\n",
    "        pip.main( ['install', 'kaggle'] )\n",
    "\n",
    "    # Now use a bash subprocess to download the dataset\n",
    "    subprocess = __import__( 'subprocess' )\n",
    "\n",
    "    downloadCommand = \"kaggle datasets download -d squanch/maskimageset\" # Hope you're a Rick & Morty fan! As I was 5 years ago\n",
    "    \n",
    "    commandResult = subprocess.run( downloadCommand, \n",
    "                                   shell = True, \n",
    "                                   stdout = subprocess.PIPE,\n",
    "                                   stderr = subprocess.PIPE,\n",
    "                                   text = True\n",
    "                                   )\n",
    "    \n",
    "    if commandResult.returncode != 0 or os.path.exists( './maskimageset.zip' ):\n",
    "        raise Exception( \"Data failed to download. Please check your API key, or try manually.\" )\n",
    "    \n",
    "    # Now unzip the file\n",
    "    try:\n",
    "        zipfile = __import__( 'zipfile' )\n",
    "        with zipfile.ZipFile( './maskimageset.zip' ) as zipObj:\n",
    "            zipObj.extractall()\n",
    "\n",
    "    except:\n",
    "        raise Exception( \"Data failed to unzip. Unzip it yourself.\" )\n",
    "    \n",
    "    # Remove the original zipped file from the working directory\n",
    "    if os.path.exists( './maskimageset.zip' ):\n",
    "        os.remove( './maskimageset.zip' )\n",
    "\n",
    "    # And we're done! There should be a completely hydrated folder called 'mask_image_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function and watch the data downloading magic happen!\n",
    "# NOTE: I changed the folder names to 'trainingData', 'testData', 'validationData'; I don't like unclear names anymore\n",
    "\n",
    "downloadAndUnzipData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the PyTorch DataLoader & Dataset\n",
    "\n",
    "**Dataset** - the structure that organizes the images and labels\n",
    "\n",
    "**DataLoader** - generator that yields data batches for model-training at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set some settings!\n",
    "\n",
    "settings = {\n",
    "    'DATASET_PATH': './mask_image_set/', # Should be local if you've performed the above, otherwise change it\n",
    "    'NUM_CLASSES': '2', # Masked or non-masked\n",
    "    'BATCH_SIZE': '64',\n",
    "    'NUM_EPOCHS': '25', # How many levels of training do you want?\n",
    "    'FEATURE_EXTRACTION': 'ON', # Only update reshaped layer parameters (otherwise set to empty string)\n",
    "    'IMAGE_SIZE': '224', # Standardize all input images to a square image of 224px\n",
    "    'RUNTIME_DEVICE': 'cuda:0' if torch.cuda.is_available() else 'cpu' # Use CUDA if available!\n",
    "}\n",
    "\n",
    "os.environ.update( settings )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and validation data from their respective folders!\n",
    "\n",
    "# Common mean and standard deviation selection for ImageNet normalization (for DataTransforms)\n",
    "normalizationMean, normalizationSTD = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "\n",
    "# DataTransforms for trainingData and validationData (changed folder names because we don't like names like 'train', 'test', 'val')\n",
    "DataTransforms = {\n",
    "    'trainingData': transforms.Compose( [\n",
    "        transforms.RandomResizedCrop( int( os.environ.get('IMAGE_SIZE', '224') ) ), # Random Crop\n",
    "        transforms.RandomHorizontalFlip(), # Random Horizontal Flip\n",
    "        transforms.ToTensor(), # Conversion to Tensor\n",
    "        transforms.Normalize( normalizationMean, normalizationSTD )\n",
    "    ]),\n",
    "\n",
    "    'validationData': transforms.Compose( [\n",
    "        transforms.Resize( int( os.environ.get('IMAGE_SIZE', '224') ) ),\n",
    "        transforms.CenterCrop( int( os.environ.get('IMAGE_SIZE', '224') )),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize( normalizationMean, normalizationSTD )\n",
    "    ])\n",
    "}\n",
    "\n",
    "# FOLDER_NAMES to eliminate redundancy moving forward ( NOTE: I changed folder names )\n",
    "FOLDER_NAMES = ('trainingData', 'validationData')\n",
    "\n",
    "getFolderPath = lambda fileFolder : os.path.join( os.environ.get('DATASET_PATH'), fileFolder ) \n",
    "\n",
    "# Map our DataTransforms and create trainingData and validationData datasets\n",
    "ImageDatasets = { \n",
    "    currentFolder: datasets.ImageFolder( getFolderPath( currentFolder ), \\\n",
    "                                      DataTransforms[ currentFolder ] ) \\\n",
    "                for currentFolder in FOLDER_NAMES\n",
    "}\n",
    "\n",
    "\n",
    "# Create trainingData and validationData DataLoaders\n",
    "ImageDataLoaders = {\n",
    "    currentFolder: torch.utils.data.DataLoader( ImageDatasets[ currentFolder ], \\\n",
    "                                             batch_size = int( os.environ.get('BATCH_SIZE') ), \\\n",
    "                                             shuffle = True, \\\n",
    "                                             num_workers = 4 ) \\\n",
    "                for currentFolder in FOLDER_NAMES\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing our model\n",
    "\n",
    "This VGG-11 classifier model has learned to classify 1,000 classes! We are setting up a simple binary classification (masked/non-masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If feature extraction is turned on, we will freeze all of the layers except the last\n",
    "def setGradientRequirements( model, feature_extraction_on = bool( os.environ.get('FEATURE_EXTRACTION', '') ) ):\n",
    "    if feature_extraction_on:\n",
    "        for parameter in model.parameters():\n",
    "            parameter.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do some setup!\n",
    "\n",
    "# Our pre-trained VGG-11 image classifier\n",
    "classificationModel = models.vgg11_bn( pretrained = True )\n",
    "\n",
    "# Set gradient requirements (using the function defined above)\n",
    "setGradientRequirements( model = classificationModel )\n",
    "\n",
    "# Number of input features to model's forward method\n",
    "lastLayer = 6\n",
    "numInputFeatures = classificationModel.classifier[ lastLayer ].in_features\n",
    "\n",
    "# Change the dimension of the last layer to 2 (we're performing binary classification)\n",
    "classificationModel.classifier[ lastLayer ] = nn.Linear( numInputFeatures, lastLayer )\n",
    "\n",
    "# Create a Torch device based on CUDA availability and move our model there!\n",
    "runtimeDevice = torch.device( os.environ.get(\"RUNTIME_DEVICE\", 'cpu') )\n",
    "classificationModel.to( runtimeDevice )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Optimization\n",
    "\n",
    "Here we set up our model optimizer and loss metric. In deep learning, loss metrics are used to evaluate how close our predictions were to the \"ground truth\". Smaller loss means better performance. The optimizer computes gradients and minimizes loss at each training step.\n",
    "\n",
    "We use a **stochastic gradient descent** as our optimizer and **cross-entropy** as our loss metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set up our model optimizer and loss metric\n",
    "\n",
    "# Stochastic gradient descent (model optimizer)\n",
    "modelOptimizer = optim.SGD( \n",
    "    classificationModel.parameters(),\n",
    "    lr = 0.001, # Learning rate (play around with this for best accuracy)\n",
    "    momentum = 0.9\n",
    ")\n",
    "\n",
    "# Cross entropy (loss metric)\n",
    "lossMetric = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the fun stuff -- let's train!\n",
    "\n",
    "The function below uses all of the setup we have done to train the model and visualize training and validation loss & accuracy at each step. At the end, we can see the model at its best and the amount of time training took (feel free to change the time to each \"epoch\" or training cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's train our model! \n",
    "\n",
    "def trainModel( model, dataloaders, criterion, optimizer, num_epochs ):\n",
    "\n",
    "    '''\n",
    "    Function to train a model using particular datasets, optimizer, and loss function\n",
    "\n",
    "    Args:\n",
    "    - model: a pre-defined neural network model\n",
    "    - dataloaders: a dictionary containing the training and validation data loaders\n",
    "    - criterion: the loss function used to measure the error of the model's output\n",
    "    - optimizer: the optimization algorithm used to adjust the model's parameters\n",
    "    - num_epochs: the number of times the entire dataset is passed through the model during training \n",
    "\n",
    "    Returns:\n",
    "    - model: the trained model\n",
    "    '''\n",
    "    \n",
    "    # Process startTime\n",
    "    startTime = time.time()\n",
    "\n",
    "    # Validation Accuracy History - % of correctly classified images at \n",
    "    # the end of each training epoch\n",
    "    accuracyLog = []\n",
    "    \n",
    "    # Highest model accuracy and set of model weights\n",
    "    bestModelWeights = copy.deepcopy( model.state_dict() )\n",
    "    highestAccuracy = 0.0\n",
    "\n",
    "    # Training Epochs\n",
    "    for currentEpoch in range(1, (num_epochs + 1) ):\n",
    "\n",
    "      # Log currentEpoch to console\n",
    "\n",
    "      logText = 'Epoch {}/{}'.format(currentEpoch, num_epochs)\n",
    "      print( logText )\n",
    "\n",
    "      print( '-' * len( logText ) ) # Number of dashes changes with text length\n",
    "\n",
    "      # Each epoch has a training and validation phase\n",
    "      PHASES = ('Training', 'Validation')\n",
    "\n",
    "      # Reset the currentFolder to trainingData in each epoch\n",
    "      currentFolder = 'trainingData'\n",
    "      \n",
    "      # Toggle between training phase and validation phase\n",
    "      for currentPhase in PHASES:\n",
    "          \n",
    "          # If we are in the training phase, set the model to training mode\n",
    "          if currentPhase == 'Training':\n",
    "              model.train()\n",
    "\n",
    "          # Otherwise, set the model to evaluation mode\n",
    "          else:\n",
    "              model.eval()\n",
    "              currentFolder = 'validationData' # Toggle currentFolder to validationData\n",
    "\n",
    "          # Continually track the number of correct predictions\n",
    "          # and the average loss of the model on the trainingData\n",
    "          numCorrect, runningLoss = 0, 0.0\n",
    "\n",
    "          # Iterate through the datasets\n",
    "          for modelInputs, targetOutput in dataloaders[ currentFolder ]:\n",
    "              \n",
    "              # Write the inputs and outputs to the RuntimeDevice\n",
    "              modelInputs, targetOutput = modelInputs.to( runtimeDevice ), targetOutput.to( runtimeDevice )\n",
    "\n",
    "              # Zero the parameter gradients at the beginning of each iteration \n",
    "              optimizer.zero_grad()\n",
    "\n",
    "              # Move our model forwards\n",
    "              # Track history if we are in the training phase (but not in the evalution phase)\n",
    "              with torch.set_grad_enabled( currentPhase == 'Training' ):\n",
    "                  \n",
    "                  # Obtain model outputs\n",
    "                  modelOutputs = model( modelInputs )\n",
    "\n",
    "                  # Update the LossFunction and modelPredictions\n",
    "                  LossFunction = criterion( modelOutputs, targetOutput )\n",
    "                  _, modelPredictions = torch.max( modelOutputs, 1 )\n",
    "\n",
    "                  # If we are in the training phase, move the LossFunction backwards and optimize\n",
    "                  if currentPhase == 'Training':\n",
    "                      LossFunction.backward()\n",
    "                      optimizer.step()\n",
    "\n",
    "              # Update our runningLoss and our number of correct predictions\n",
    "              runningLoss += LossFunction.item() * modelInputs.size(0)\n",
    "              numCorrect += torch.sum( modelPredictions == targetOutput.data)\n",
    "\n",
    "          # The loss over the epoch is the loss so far / the size of the dataset\n",
    "          epochLoss = runningLoss / len( dataloaders[ currentFolder ].dataset )\n",
    "\n",
    "          # The epoch accuracy is the number of correct predictions / the size of the dataset\n",
    "          epochAccuracy = numCorrect.double() / len( dataloaders[ currentFolder ].dataset )\n",
    "\n",
    "          # Print to console\n",
    "          print( '{} | Loss: {:.4f} Accuracy: {:.4f}'.format( currentPhase, epochLoss, epochAccuracy ) )\n",
    "\n",
    "          # If we are in the validation phase, deep copy the model\n",
    "          if currentPhase == 'Validation':\n",
    "\n",
    "            # Update the highestAccuracy and bestModelWeights if we have encountered bettter accuracy\n",
    "            if epochAccuracy > highestAccuracy:\n",
    "              highestAccuracy = epochAccuracy\n",
    "              bestModelWeights = copy.deepcopy( model.state_dict() )\n",
    "          \n",
    "            # Add the epoch's accuracy to the accuracyLog\n",
    "            accuracyLog.append( epochAccuracy )\n",
    "\n",
    "      print() # Blank line\n",
    "\n",
    "    # Total elapsedTime\n",
    "    elapsedTime = time.time() - startTime\n",
    "\n",
    "    # Log process time and model performance to console\n",
    "    print('\\n\\nTraining time: {:.0f}m {:.0f}s'.format( elapsedTime // 60, elapsedTime % 60 ) )\n",
    "    print('Highest validation accuracy: {:.4f}%'.format( highestAccuracy * 100 ) )\n",
    "\n",
    "    # Load the bestModelWeights\n",
    "    model.load_state_dict( bestModelWeights )\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fineTunedModel = trainModel( \n",
    "    model = classificationModel, \n",
    "    dataloaders = ImageDataLoaders, \n",
    "    criterion = lossMetric, \n",
    "    optimizer = modelOptimizer, \n",
    "    num_epochs = int( os.environ.get('NUM_EPOCHS') ) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... And let's see how we did! (Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the testData transforms to our DataTransforms HashMap, and set it equal to our training data transforms\n",
    "\n",
    "# NOTE: This takes forever on a CPU! I highly suggest you get a nice T4 Nvidia runtime & breeze through this\n",
    "\n",
    "DataTransforms[ 'testData' ] = DataTransforms[ 'trainingData' ]\n",
    "\n",
    "# Create our test dataset\n",
    "ImageDatasets[ 'testData' ] = datasets.ImageFolder( get_folder_path( 'testData' ),\n",
    "                                                    DataTransforms['testData'] )\n",
    "\n",
    "# Create our test DataLoader\n",
    "\n",
    "ImageDataLoaders[ 'testData' ] = torch.utils.data.DataLoader( ImageDatasets['testData'],\n",
    "                                                              batch_size = BATCH_SIZE,\n",
    "                                                              shuffle = True,\n",
    "                                                              num_workers = 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's assume this model has been trained (which it was in Colab, but migrated locally)\n",
    "# And test our model!\n",
    "\n",
    "def testModel( model, dataloader ):\n",
    "  \n",
    "  '''\n",
    "  Function to test the performance of a trained model on a test dataset\n",
    "\n",
    "  Arguments:\n",
    "  - model (nn.Module): trained image classification model to be tested\n",
    "  - dataloader (DataLoader): PyTorch DataLoader object for the test dataset\n",
    "\n",
    "  Returns:\n",
    "  - testAccuracy (float): the classification accuracy of the model\n",
    "  '''\n",
    "\n",
    "  # First, we set the model to evaluation mode\n",
    "  model.eval()\n",
    "\n",
    "  # Track the # of correct predictions and the # of total predictions\n",
    "  numCorrect, numPredictions = 0, 0\n",
    "\n",
    "\n",
    "  with torch.no_grad(): # Gradients are not needed in inference/validation\n",
    "\n",
    "    # Iterate over the test dataset   \n",
    "    for modelInputs, targetOutput in dataloader:\n",
    "\n",
    "      # Move the modelInputs and targetOutputs to the RuntimeDevice\n",
    "      modelInputs, targetOutput = modelInputs.to( runtimeDevice ), targetOutput.to( runtimeDevice )\n",
    "\n",
    "      # Predict!\n",
    "      modelOutput = model( modelInputs )\n",
    "      _, modelPrediction = torch.max( modelOutput, 1 )\n",
    "\n",
    "      # Update the numCorrect and numPredictions\n",
    "      numCorrect += (modelPrediction == targetOutput).sum().item()\n",
    "      numPredictions += targetOutput.size(0)\n",
    "\n",
    "  # Calculate testAccuracy ( return object )\n",
    "  testAccuracy = numCorrect / numPredictions\n",
    "\n",
    "  # Log testAccuracy to console\n",
    "  print( 'Test Accuracy: {:.2f}%'.format( testAccuracy * 100 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel( model = fineTunedModel,\n",
    "            dataloader = ImageDataLoaders['testData'] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
